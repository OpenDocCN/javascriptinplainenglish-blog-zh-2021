<html>
<head>
<title>Machine Learning Theory and Programming: Supervised Learning for Multiclass Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习理论和编程:多类分类的监督学习</h1>
<blockquote>原文：<a href="https://javascript.plainenglish.io/machine-learning-theory-and-programming-supervised-learning-for-multiclass-classification-ee0d9d32150e?source=collection_archive---------11-----------------------#2021-10-26">https://javascript.plainenglish.io/machine-learning-theory-and-programming-supervised-learning-for-multiclass-classification-ee0d9d32150e?source=collection_archive---------11-----------------------#2021-10-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="5007" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一种流行的机器学习算法介绍。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/5081d6e18afd938f49de830f41289e0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QKZ-fkg2CgYPwjBPoYdc9w.jpeg"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Image by Author</figcaption></figure><p id="2eb6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们走过了很多有监督的<a class="ae lb" href="https://en.wikipedia.org/wiki/Machine_learning" rel="noopener ugc nofollow" target="_blank">机器学习</a>算法、<a class="ae lb" href="https://betterprogramming.pub/machine-learning-theory-and-programming-supervised-learning-regression-analysis-8ed2d86f5714" rel="noopener ugc nofollow" target="_blank">线性回归、多项式回归</a>、<a class="ae lb" href="https://enlear.academy/logistic-regression-in-machine-learning-672c0e8c8053" rel="noopener ugc nofollow" target="_blank">逻辑回归</a>、<a class="ae lb" href="https://medium.com/geekculture/machine-learning-theory-and-programming-supervised-learning-neural-networks-74a598cb9e42" rel="noopener">神经网络</a>、<a class="ae lb" rel="noopener ugc nofollow" target="_blank" href="/machine-learning-theory-and-programming-supervised-learning-support-vector-machine-d6cc7a5747f1">支持向量机</a> (SVMs)。监督学习建立了一组数据的数学模型，其中包含输入(<code class="fe lc ld le lf b">x</code>)和正确的输出(<code class="fe lc ld le lf b">y</code>)。</p><p id="7490" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">二元分类器只有两种可能的输出。我们写了两篇文章来训练二进制分类器。在这里，我们将展示如何执行多类分类。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><h1 id="34b5" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated"><strong class="ak"> <em class="ml">多类分类理论</em> </strong></h1><p id="c0cb" class="pw-post-body-paragraph jn jo iq jp b jq mm js jt ju mn jw jx jy mo ka kb kc mp ke kf kg mq ki kj kk ij bi translated"><a class="ae lb" href="https://en.wikipedia.org/wiki/Multiclass_classification" rel="noopener ugc nofollow" target="_blank">多类分类</a>将实例分为三类或更多类。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mr"><img src="../Images/95a368abe7be47634442eae96768d521.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X6kpyYH-GZJPAVs4USJgBA.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Image Credit: Wikipedia</figcaption></figure><p id="79b0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae lb" href="https://en.wikipedia.org/wiki/Iris_flower_data_set" rel="noopener ugc nofollow" target="_blank"> Fisher的虹膜数据</a>是模式识别文献中最著名的数据库。它包括对150种鸢尾属植物的萼片长度、萼片宽度、花瓣长度和花瓣宽度的测量(以<code class="fe lc ld le lf b">cm</code>为单位)。<code class="fe lc ld le lf b">setosa</code>、<code class="fe lc ld le lf b">versicolor</code>、<code class="fe lc ld le lf b">virginica</code>三个物种各50个标本。我们关注花瓣长度和花瓣宽度，它们是<code class="fe lc ld le lf b">meas</code>矩阵中的第3列和第4列。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/240c3deafddde3c6e96bb5d83544d591.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*cji8UvB8hGzMZYL5cWEmDw.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Image by Author</figcaption></figure><p id="8ceb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在之前的文章中，我们使用了线性SVM模型对<code class="fe lc ld le lf b">'versicolor'</code>和<code class="fe lc ld le lf b">'virginica'</code>进行分类。我们还使用高斯SVM模型在<code class="fe lc ld le lf b">'versicolor'</code>和<code class="fe lc ld le lf b">'non-versicolor'</code>之间进行分类。</p><p id="afee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">多类分类可以被视为多个一对一的分类问题。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mt"><img src="../Images/122a6a06ca4de0ae8582733921446af1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TBIbOoAr11WWKuIRBv1vhw.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Image by Authour</figcaption></figure><p id="5d34" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于虹膜数据集，我们创建三个二元分类器:</p><ul class=""><li id="d0df" class="mu mv iq jp b jq jr ju jv jy mw kc mx kg my kk mz na nb nc bi translated">从<code class="fe lc ld le lf b">'non-setosa'</code>预测<code class="fe lc ld le lf b">'setosa'</code>的<code class="fe lc ld le lf b">setosa</code>分类器</li><li id="cbed" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated">从<code class="fe lc ld le lf b">'non-versicolor'</code>预测<code class="fe lc ld le lf b">'versicolor'</code>的<code class="fe lc ld le lf b">versicolor</code>分类器</li><li id="dcbb" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated">从<code class="fe lc ld le lf b">'non-virginica'</code>预测<code class="fe lc ld le lf b">'virginica'</code>的<code class="fe lc ld le lf b">virginica</code>分类器</li></ul><p id="c3c4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于每个新数据，得到三个预测分数，然后选择最新的值。产生最新值的二元分类器是预测类。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><h1 id="d7aa" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">多类分类编程</h1><p id="4b08" class="pw-post-body-paragraph jn jo iq jp b jq mm js jt ju mn jw jx jy mo ka kb kc mp ke kf kg mq ki kj kk ij bi translated">有机器学习专用的编程语言，如<a class="ae lb" href="https://matlab.mathworks.com/" rel="noopener ugc nofollow" target="_blank"> MATLAB </a>、<a class="ae lb" href="https://www.gnu.org/software/octave/index" rel="noopener ugc nofollow" target="_blank"> Octave </a>、<a class="ae lb" href="https://betterprogramming.pub/exploring-the-ai-programming-language-r-102d25af9646" rel="noopener ugc nofollow" target="_blank"> R </a>等。对于一些通用编程语言，如Python，它们提供了机器学习库。强烈建议不要多此一举。我们可以使用机器学习特定的编程语言或机器学习库来解决多类分类问题。</p><p id="bfed" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">MATLAB是MathWorks开发的专有多范式编程语言和数值计算环境。它提供了一个内置函数，<em class="ni">k</em>-均值聚类</p><ul class=""><li id="dd5a" class="mu mv iq jp b jq jr ju jv jy mw kc mx kg my kk mz na nb nc bi translated"><code class="fe lc ld le lf b"><a class="ae lb" href="https://www.mathworks.com/help/stats/fitcsvm.html#bt8v_z4-1" rel="noopener ugc nofollow" target="_blank">fitcsvm</a></code>在低维或中维预测数据集上训练用于一类和二类(二元)分类的SVM模型。</li><li id="38dc" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated"><code class="fe lc ld le lf b"><a class="ae lb" href="https://www.mathworks.com/help/stats/fitcecoc.html" rel="noopener ugc nofollow" target="_blank">fitcecoc</a></code>为SVM或其他分类器训练多类模型。<code class="fe lc ld le lf b">ClassificationECOC</code>是一个用于多类学习的纠错输出码(ECOC)分类器，其中分类器由多个二进制学习器组成。</li></ul><h2 id="256e" class="nj lo iq bd lp nk nl dn lt nm nn dp lx jy no np mb kc nq nr mf kg ns nt mj nu bi translated">三个二元分类器</h2><p id="403b" class="pw-post-body-paragraph jn jo iq jp b jq mm js jt ju mn jw jx jy mo ka kb kc mp ke kf kg mq ki kj kk ij bi translated">这是一个使用三个二元分类器来解决虹膜分类问题的程序。它用不同的颜色绘制预测区域。iris训练集中的输入显示在用于验证的区域的顶部。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="53c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第1行指定了函数名<code class="fe lc ld le lf b">ThreeBinaryClassifiers</code>。</p><p id="1cf5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第3-5行加载数据集<code class="fe lc ld le lf b">fisheriris</code>，并将数据分配给<code class="fe lc ld le lf b">X</code>和<code class="fe lc ld le lf b">y</code>。<code class="fe lc ld le lf b">X</code>获取第3列和第4列虹膜数据，即花瓣长度和花瓣宽度。<code class="fe lc ld le lf b">y</code>是抄袭<code class="fe lc ld le lf b">species</code>的单元数组。</p><p id="547e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第8–13行训练3个二元分类器，<code class="fe lc ld le lf b">SVMModels</code>。有3个独特的类，<code class="fe lc ld le lf b">'setosa'</code>、<code class="fe lc ld le lf b">'versicolor</code>和<code class="fe lc ld le lf b">'virginica'</code>。<code class="fe lc ld le lf b">numel(classes)</code>返回3。它将当前类作为正例，<code class="fe lc ld le lf b">fitcsvm</code>用核函数<code class="fe lc ld le lf b">'gaussian'</code>训练每个SVM模型。</p><p id="abda" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第16-26行生成二维网格上的每个点，<code class="fe lc ld le lf b">xGrid</code>。密度由<code class="fe lc ld le lf b">d</code>(第16行)定义。<code class="fe lc ld le lf b">meshgrid(x, y)</code>根据矢量<code class="fe lc ld le lf b">x</code>和<code class="fe lc ld le lf b">y</code>中包含的坐标返回二维网格坐标。对于每个点，它预测3个二元分类器的得分，并将结果存储在<code class="fe lc ld le lf b">Scores</code>中。</p><p id="f272" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第29–31行在二维网格上绘制每个点。每个点选择产生最新值的相应分类器的颜色。如果是来自<code class="fe lc ld le lf b">'setosa'</code>，颜色为青色(<code class="fe lc ld le lf b">'c'</code>)。如果是来自<code class="fe lc ld le lf b">'versicolor</code>，颜色是洋红色(<code class="fe lc ld le lf b">'m'</code>)。如果是来自<code class="fe lc ld le lf b">'virginica'</code>，颜色是黄色(<code class="fe lc ld le lf b">'y'</code>)。<code class="fe lc ld le lf b">max(Scores, [], 2)</code>第29行返回一个包含每行最大值的列向量。第31行调用<code class="fe lc ld le lf b">hold on</code>保留当前轴中的图，这样添加到轴中的新图不会删除现有的图。</p><p id="3088" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第34行在用于验证的区域的顶部绘制虹膜训练集<code class="fe lc ld le lf b">X</code>。</p><p id="d7a3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第37–42行绘制标题、轴标签和图例。</p><p id="3200" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第43行设置数据范围的轴限制。</p><p id="8c6d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第44行调用<code class="fe lc ld le lf b">hold off</code>将保持状态设置为关闭。</p><p id="a95b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第45行终止该函数。</p><p id="545b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下是生成的带有预测区域的图表:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/5973d06425a6a44b97c934aef4e8bba7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*OZCLfdWR1A-2_l1zgctTqw.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Image by Author</figcaption></figure><h2 id="b2bf" class="nj lo iq bd lp nk nl dn lt nm nn dp lx jy no np mb kc nq nr mf kg ns nt mj nu bi translated">多类分类器</h2><p id="b62c" class="pw-post-body-paragraph jn jo iq jp b jq mm js jt ju mn jw jx jy mo ka kb kc mp ke kf kg mq ki kj kk ij bi translated">正如我们已经说过的，尽量不要重新发明轮子。有一个内置函数<code class="fe lc ld le lf b">fitcecoc</code>，它训练多类分类器。尽管它是一个由多个二进制学习器组成的分类器，我们仍然应该使用这个内置的多类分类模型。它使用后验区域(条件概率)来显示预测的可能性。</p><p id="42ff" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面的程序更短，并且提供了更复杂的结果。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="e10f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第1行指定了函数名<code class="fe lc ld le lf b">MulticlassClassifier</code>。</p><p id="2152" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第3-5行加载数据集<code class="fe lc ld le lf b">fisheriris</code>，并将数据分配给<code class="fe lc ld le lf b">X</code>和<code class="fe lc ld le lf b">y</code>。<code class="fe lc ld le lf b">X</code>取虹膜数据的第3列和第4列，分别是花瓣长度和花瓣宽度。<code class="fe lc ld le lf b">y</code>是从<code class="fe lc ld le lf b">species</code>复制过来的单元格数组。</p><p id="0795" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第8–9行训练多类分类器<code class="fe lc ld le lf b">Mdl</code>。第8行返回一个SVM学习者模板<code class="fe lc ld le lf b">templateSVM</code>，它适合于训练多类模型。第9行训练多类分类器，并将分类分数转换为类后验概率。<code class="fe lc ld le lf b">'Verbose'</code>级别设置为2，显示培训过程的信息。</p><p id="bb90" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第12-15行生成二维网格上的每个点，<code class="fe lc ld le lf b">xGrid</code>。密度由<code class="fe lc ld le lf b">d</code>(第12行)定义。<code class="fe lc ld le lf b">meshgrid(x, y)</code>根据矢量<code class="fe lc ld le lf b">x</code>和<code class="fe lc ld le lf b">y</code>中包含的坐标返回二维网格坐标。对于每个点，它预测后验概率。结果在<code class="fe lc ld le lf b">PosteriorRegion</code>(第15行)中被捕获。</p><p id="c73c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第18–22行描绘了最大的后部区域。<code class="fe lc ld le lf b">contourf</code>填充2-D轮廓图，它是由类别后验概率整形的坐标。它会创建一个包含同类后验概率值等值线的填充等值线图。第20行创建了一个颜色条，用于映射颜色和后验值。在<code class="fe lc ld le lf b">southoutside</code>处给棒材贴上标签并设定位置。第22行调用<code class="fe lc ld le lf b">hold on</code>保留当前轴中的图，这样添加到轴中的新图不会删除现有的图。</p><p id="573a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第25行在用于验证的区域的顶部绘制虹膜训练集。</p><p id="ed87" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第28–31行绘制标题、轴标签和图例。</p><p id="e20f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第32行设置了数据范围的轴限制。</p><p id="1d6d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第33行调用<code class="fe lc ld le lf b">hold off</code>将保持状态设置为关闭。</p><p id="af16" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第34行终止该函数。</p><p id="0b81" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下图显示了最大后验分布:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/96062d345af2614fd623b22f1823ca17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*1aXMs44bsg2jhUnYd3RIBQ.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Image by Author</figcaption></figure><p id="3c77" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下是3名学员的详细控制台输出:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nv nw l"/></div></figure></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><h1 id="1419" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">结论</h1><p id="873d" class="pw-post-body-paragraph jn jo iq jp b jq mm js jt ju mn jw jx jy mo ka kb kc mp ke kf kg mq ki kj kk ij bi translated">有很多机器学习算法。在本文中，我们提出了用于多类分类的监督学习。机器学习编程语言设计有预建的库和对数据科学和数据模型的高级支持。我们已经展示了使用MATLAB实现3个二元分类器和1个多分类器的例子。</p><p id="9ba0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下是其他机器学习算法的列表:</p><ul class=""><li id="1781" class="mu mv iq jp b jq jr ju jv jy mw kc mx kg my kk mz na nb nc bi translated"><a class="ae lb" href="https://betterprogramming.pub/machine-learning-theory-and-programming-supervised-learning-regression-analysis-8ed2d86f5714" rel="noopener ugc nofollow" target="_blank">回归分析</a></li><li id="9b42" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated"><a class="ae lb" href="https://enlear.academy/logistic-regression-in-machine-learning-672c0e8c8053" rel="noopener ugc nofollow" target="_blank">逻辑回归</a></li><li id="25e7" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated"><a class="ae lb" href="https://medium.com/geekculture/machine-learning-theory-and-programming-supervised-learning-neural-networks-74a598cb9e42" rel="noopener">神经网络</a></li><li id="12bb" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated"><a class="ae lb" rel="noopener ugc nofollow" target="_blank" href="/machine-learning-theory-and-programming-supervised-learning-support-vector-machine-d6cc7a5747f1">支持向量机</a></li><li id="c035" class="mu mv iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated"><a class="ae lb" rel="noopener ugc nofollow" target="_blank" href="/machine-learning-theory-and-programming-unsupervised-learning-k-means-clustering-52eeea41cba0"> K均值聚类</a></li></ul><p id="d3a4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">感谢阅读。我希望这有所帮助。如果你有兴趣，可以看看<a class="ae lb" href="https://jenniferfubook.medium.com/jennifer-fus-web-development-publications-1a887e4454af" rel="noopener">我的其他媒体文章</a>。</p><p id="ae45" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="ni">注:</em> </strong> <em class="ni">感谢Josh Poduska、Andrew Ziegler、Subir Mansukhani推荐机器学习资源！还有，感谢吴恩达教授的</em> <a class="ae lb" href="https://www.coursera.org/learn/machine-learning" rel="noopener ugc nofollow" target="_blank"> <em class="ni">机器学习课</em> </a> <em class="ni">。</em></p><p id="bc23" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="ni">更多内容请看</em><a class="ae lb" href="http://plainenglish.io/" rel="noopener ugc nofollow" target="_blank"><strong class="jp ir"><em class="ni">plain English . io</em></strong></a></p></div></div>    
</body>
</html>