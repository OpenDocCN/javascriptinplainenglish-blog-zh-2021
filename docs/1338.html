<html>
<head>
<title>Build Your Own Neural Network with JavaScript</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用JavaScript构建自己的神经网络</h1>
<blockquote>原文：<a href="https://javascript.plainenglish.io/make-your-own-neural-network-app-with-plain-javascript-and-a-tiny-bit-of-math-js-30ab5ff4cbd5?source=collection_archive---------4-----------------------#2021-03-21">https://javascript.plainenglish.io/make-your-own-neural-network-app-with-plain-javascript-and-a-tiny-bit-of-math-js-30ab5ff4cbd5?source=collection_archive---------4-----------------------#2021-03-21</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/6af94e555d4d6ea35c4dd2a2d481ca40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Dl1gjOdLm3jgBD9n"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">Photo by <a class="ae jz" href="https://unsplash.com/@mockupgraphics?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Mockup Graphics</a> on <a class="ae jz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="94df" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">开始深度学习真的不一定非得是Python。JavaScript为您提供了从头创建自己的神经网络所需的一切。使用JavaScript的最大好处和明显优势是，您可以快速地将您的模型嵌入到正在运行的应用程序中——无论是通过web还是通过React Native在移动设备上提供。在这篇文章中，我将向你展示如何通过训练和实现你自己的神经网络来创建一个识别手写数字的web应用程序。你所需要的只是普通的JavaScript和一点点库<a class="ae jz" href="https://mathjs.org" rel="noopener ugc nofollow" target="_blank"> mathJS </a>。</p><p id="cf6e" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">在我的第一篇<a class="ae jz" rel="noopener ugc nofollow" target="_blank" href="/how-to-run-ai-models-locally-in-the-smartphone-with-react-native-and-tensorflow-js-666f52fd15ca">文章</a>中，我展示了如何实现现有深度学习模型(转换为Tensorflow.js)的概念验证，以便它们可以在移动设备上本地运行，而在本文中，重点将真正放在从头创建一个模型上。我假设你对神经网络如何工作有基本到高级的理解——我将快速回顾一下像反向传播这样的概念，并包括进一步的有用阅读。</p><p id="4f57" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">如果你对神经网络还不太有信心，我推荐你去读一读塔里克·拉希德的精彩著作<a class="ae jz" href="http://makeyourownneuralnetwork.blogspot.co.uk" rel="noopener ugc nofollow" target="_blank">《打造你自己的神经网络》</a>。这本书极大地帮助了我理解神经网络实际上是如何在幕后工作的。所以让我们开始吧！</p><h1 id="c589" class="ky kz in bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated"><strong class="ak">项目概述</strong></h1><p id="1417" class="pw-post-body-paragraph ka kb in kc b kd lw kf kg kh lx kj kk kl ly kn ko kp lz kr ks kt ma kv kw kx ig bi translated">如上所述，我们将创建一个非常简单的网页来识别手写数字。网页分为两栏:左边一栏是训练网络，右边是游乐场。以下是详细的功能:</p><p id="2ae1" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">“培训和测试”:</p><ul class=""><li id="40e2" class="mb mc in kc b kd ke kh ki kl md kp me kt mf kx mg mh mi mj bi translated">神经网络可以被训练，也可以立即用当前权重进行测试。</li></ul><p id="af2d" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">“预测”:</p><ul class=""><li id="b3d3" class="mb mc in kc b kd ke kh ki kl md kp me kt mf kx mg mh mi mj bi translated">可以在HTML画布上绘制一个数字，然后用于网络识别。</li></ul><p id="323f" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">“加载/保存重量”:</p><ul class=""><li id="4090" class="mb mc in kc b kd ke kh ki kl md kp me kt mf kx mg mh mi mj bi translated">训练后，所有的权重都可以保存在一个JSON文件中。</li><li id="f5c4" class="mb mc in kc b kd mk kh ml kl mm kp mn kt mo kx mg mh mi mj bi translated">您可以使用当前权重进行预测，也可以从保存的JSON文件中加载权重并使用它们。</li></ul><p id="40e3" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">以下是最终网页功能的截图:</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi mp"><img src="../Images/01a0d91723abde95d57496c078f18be8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*upzDUqMyt23ei1s1VVykBQ.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">Final web page’s main features</figcaption></figure><ul class=""><li id="f021" class="mb mc in kc b kd ke kh ki kl md kp me kt mf kx mg mh mi mj bi translated">点击“训练”按钮，训练开始，其进度记录在灰色容器中。在每个训练周期或迭代之后，训练好的网络被测试，并且它的进度也被显示，连同度量损失和准确性。</li><li id="7055" class="mb mc in kc b kd mk kh ml kl mm kp mn kt mo kx mg mh mi mj bi translated">通过点击“测试”按钮，根据测试数据集测试当前模型。</li><li id="e617" class="mb mc in kc b kd mk kh ml kl mm kp mn kt mo kx mg mh mi mj bi translated">“加载重量”按钮只有在保存了JSON文件，且该文件中包含以前训练的重量时才可用。</li><li id="3189" class="mb mc in kc b kd mk kh ml kl mm kp mn kt mo kx mg mh mi mj bi translated">黑色方块是用户可以画一个数字的画布。一旦点击“预测”按钮，来自模型的预测就会显示在旁边的白色方形区域中。</li></ul><h1 id="abe2" class="ky kz in bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated"><strong class="ak">项目结构</strong></h1><p id="92c7" class="pw-post-body-paragraph ka kb in kc b kd lw kf kg kh lx kj kk kl ly kn ko kp lz kr ks kt ma kv kw kx ig bi translated">这里没什么特别的。在项目根目录的文件夹中只有三个文件:</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/2c2032f44bb72b2c51596ddbfdbc5272.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/format:webp/1*8LYmbLImRH2czbcEOwkkfQ.png"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">Project folder</figcaption></figure><ul class=""><li id="3328" class="mb mc in kc b kd ke kh ki kl md kp me kt mf kx mg mh mi mj bi translated">这个文件是我们所有神经网络逻辑的所在地。</li><li id="9b24" class="mb mc in kc b kd mk kh ml kl mm kp mn kt mo kx mg mh mi mj bi translated"><code class="fe mv mw mx my b">index.html</code>:我们的网页，用于将神经网络实现为一个工作应用。它导入我们的<code class="fe mv mw mx my b">nn.js</code>文件和mathJS库。</li><li id="bda9" class="mb mc in kc b kd mk kh ml kl mm kp mn kt mo kx mg mh mi mj bi translated">一些相当简单的CSS样式使我们的网页更加漂亮。</li><li id="7f15" class="mb mc in kc b kd mk kh ml kl mm kp mn kt mo kx mg mh mi mj bi translated"><code class="fe mv mw mx my b">mnist/</code>:该文件夹包含MNIST数据集，以CSV文件形式保存。您可以从<a class="ae jz" href="https://pjreddie.com/projects/mnist-in-csv/" rel="noopener ugc nofollow" target="_blank"> pjreddie </a>下载这些文件，由于大小原因，它们不会包含在<a class="ae jz" href="https://github.com/RyanLinXiang/neural-network-with-js" rel="noopener ugc nofollow" target="_blank">项目的资源库</a>中。</li><li id="7632" class="mb mc in kc b kd mk kh ml kl mm kp mn kt mo kx mg mh mi mj bi translated"><code class="fe mv mw mx my b">dist/</code>:该文件夹包含训练好的权重的JSON文件。</li></ul><h1 id="8416" class="ky kz in bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">项目数据集</h1><p id="ae69" class="pw-post-body-paragraph ka kb in kc b kd lw kf kg kh lx kj kk kl ly kn ko kp lz kr ks kt ma kv kw kx ig bi translated">我们将利用流行的手写数字的MNIST数据集来训练我们的神经网络。该数据集包括60，000个用于训练的样本和10，000个用于验证/测试的样本。该数据集具有以下特征:</p><ul class=""><li id="2379" class="mb mc in kc b kd ke kh ki kl md kp me kt mf kx mg mh mi mj bi translated">每一个数字都由一张28x28像素的灰度图片表示。数据集中“3”的示例如下:</li></ul><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/21a2b82406dbe41a04a36609d5127451.png" data-original-src="https://miro.medium.com/v2/resize:fit:56/format:webp/1*MfOXsRQ9fd5MIGuGu_PZPQ.png"/></div></figure><ul class=""><li id="f195" class="mb mc in kc b kd ke kh ki kl md kp me kt mf kx mg mh mi mj bi translated">如下图所示，每个像素可以用0-255范围内的颜色值来表示:</li></ul><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div class="gh gi na"><img src="../Images/64224f9532707adc6180f8b7be3fb9e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*vl8ME3__TCS1dnpy3g_rtg.png"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">MNIST sample of a “3” mapped with its colour codes</figcaption></figure><ul class=""><li id="0c94" class="mb mc in kc b kd ke kh ki kl md kp me kt mf kx mg mh mi mj bi translated">上面所有的颜色信息对应于CSV文件中的一行，看起来像<code class="fe mv mw mx my b">3,0,0,0,0,0,0, ..... 11,186,239,253,253,187, ...... 0,0,0,0\n</code>。每行的第一个元素以标签或以下颜色代码代表的地面真实数字开始。因此，在上面的示例中，该行以“3”开头。每行有785个逗号分隔的值，1个用于标签，784个用于颜色代码。</li></ul></div><div class="ab cl nb nc hr nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ig ih ii ij ik"><h1 id="6910" class="ky kz in bd la lb ni ld le lf nj lh li lj nk ll lm ln nl lp lq lr nm lt lu lv bi translated"><strong class="ak">构建神经网络</strong></h1><p id="f772" class="pw-post-body-paragraph ka kb in kc b kd lw kf kg kh lx kj kk kl ly kn ko kp lz kr ks kt ma kv kw kx ig bi translated">现在，我们已经看到了最终项目的所有细节、结构和数据集，让我们一步一步地编写神经网络模型:</p><h2 id="f89e" class="nn kz in bd la no np dn le nq nr dp li kl ns nt lm kp nu nv lq kt nw nx lu ny bi translated">数学</h2><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="c846" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">上面的快捷方式将使我们的代码更简洁，可读性更好，因为我们不希望在使用mathJS函数时使用它们的全名。请不要混淆<code class="fe mv mw mx my b">math.</code>和<code class="fe mv mw mx my b">Math.</code>，因为后者是由JavaScript提供的。<code class="fe mv mw mx my b">math.</code>参考流行的第三方库mathJS，从中我们将特别需要矩阵乘法函数。除此之外，mathJS还提供了各种科学计算助手。mathJS对我们来说一个很大的优势就是可以理解微积分表达式的<code class="fe mv mw mx my b">math.evaluate</code>函数。稍后您将会看到，这再次使我们的代码更容易掌握。</p><p id="458b" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">有了这些捷径，我们把我们的神经网络放到一个类中，从这个类中我们可以实例化。这增加了我们模型的可重用性。下面的代码演示了结构:</p><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="7ffa" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">正如你所看到的，我们的神经网络由两层组成(第4 &amp; 5行)。这对于MNIST数据集的<a class="ae jz" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank">巨大成果</a>来说已经足够了！构造函数需要传递一些超参数——每个超参数通过它们的变量名自我解释(第2–12行)。最后两个参数<code class="fe mv mw mx my b">wih</code>和<code class="fe mv mw mx my b">who</code>代表“<strong class="kc io">I</strong>nput-to-<strong class="kc io">h</strong>idden层的<strong class="kc io"> w </strong>八分之一”以及“<strong class="kc io">h</strong>idden-to-<strong class="kc io">o</strong>output层的<strong class="kc io"> w </strong>八分之一”。它们是可选的:如果它们被通过，那么神经网络假定你想用已经训练好的权重初始化它，如果不是，那么它将随机初始化权重(第8行&amp; 9)。</p><p id="b9bb" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">第11行是我们的激活函数——正如您从代码中可以猜到的，选择落在了<a class="ae jz" href="https://deepai.org/machine-learning-glossary-and-terms/sigmoid-function" rel="noopener ugc nofollow" target="_blank"> sigmoid函数</a>上。使用<code class="fe mv mw mx my b">mmap</code>(mathJS '<code class="fe mv mw mx my b">math.map</code>的简写)我们可以传入一个矩阵作为第一个参数，它将在每个元素上应用激活函数，作为第二个参数传入。</p><p id="7844" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">请记住，我们需要通过使用<code class="fe mv mw mx my b">math.matrix</code>将JavaScript数组转换成mathJS矩阵，我们用<code class="fe mv mw mx my b">mat</code>作为快捷方式来访问提供的所有功能。这完全等同于在Numpy中创建“ndarrays”或在Pytorch中创建“tensors”。</p><p id="5df7" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">下图显示了我们的两层模型。每层中的节点数量当然取决于您启动模型的方式，此处仅用于说明:</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi ob"><img src="../Images/7537bec99582fb11591e80c16b013937.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PvPDwfu4_QGSMNGXTtLeRA.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">Two layers neural network (created via <a class="ae jz" href="http://alexlenail.me/NN-SVG/index.html" rel="noopener ugc nofollow" target="_blank">alexlenail</a>)</figcaption></figure><p id="21af" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">现在让我们更深入地看看我们神经网络的每一种方法<code class="fe mv mw mx my b">forward</code>、<code class="fe mv mw mx my b">backward</code>、<code class="fe mv mw mx my b">update</code>、<code class="fe mv mw mx my b">predict</code>、<code class="fe mv mw mx my b">train</code>(上面代码片段的第18–22行)。顾名思义，它们实现前向/后向传播，然后在我们网络的训练过程中更新权重。在向您介绍代码之前，我将先给你一个方法一个方法地快速回顾一下基本概念。</p><h2 id="2ae7" class="nn kz in bd la no np dn le nq nr dp li kl ns nt lm kp nu nv lq kt nw nx lu ny bi translated">正向传播</h2><p id="4ff5" class="pw-post-body-paragraph ka kb in kc b kd lw kf kg kh lx kj kk kl ly kn ko kp lz kr ks kt ma kv kw kx ig bi translated"><strong class="kc io">快速回顾</strong>:前向传播的目标是当我们输入某些值(例如，在我们的例子中，手写数字的像素颜色代码)并将其乘以可调的所谓权重值时，从神经网络中获得预测。对于每一层，正向特性可以用两个函数来描述:首先，我们有以下描述两个矩阵的点积(加权和)的线性函数——为了简单起见，我们可以省略偏差项:</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi oc"><img src="../Images/96b442e964cefb5ae8a902975110f2c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:174/1*_xmphar13AzytMw4lyTnbw.gif"/></div></div></figure><p id="8f25" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">在我们的两层神经网络中，W可以表示输入到隐藏层或隐藏到输出层的权重矩阵。另一方面，x可以是具有隐藏层的输出值的矩阵，或者仅仅是输入值。</p><p id="0a6a" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">其次，我们需要在网络中加入非线性，因为只有这样我们才能解决更复杂的问题:</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div class="gh gi od"><img src="../Images/0e30ca9643a17b4ed048a2071f3c5431.png" data-original-src="https://miro.medium.com/v2/resize:fit:306/1*AakeUMM_ZVxl5S4w04CMpQ.gif"/></div></figure><p id="8ea6" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">sigmoid函数似乎是一个自然的选择，因为它强制其参数Z的值在0-1的范围内，这可以非常直观地理解为概率值，尤其是在输出图层中。</p><p id="88e3" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">向前传播的进一步阅读:</p><div class="oe of gp gr og oh"><a href="https://www.coursera.org/lecture/neural-networks-deep-learning/forward-propagation-in-a-deep-network-MijzH" rel="noopener  ugc nofollow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd io gy z fp om fr fs on fu fw im bi translated">深度网络中的正向传播-深度神经网络| Coursera</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">在上一个视频中，我们描述了什么是深度L层神经网络，还谈到了我们用来…</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">www.coursera.org</p></div></div><div class="oq l"><div class="or l os ot ou oq ov jt oh"/></div></div></a></div><p id="cd05" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">我们的<code class="fe mv mw mx my b">forward</code>方法将线性和非线性函数翻译成下面这段代码:</p><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="8807" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">第9-10行通过构建我们矩阵的点积<code class="fe mv mw mx my b">wih</code>和<code class="fe mv mw mx my b">input</code>(第9行)并通过sigmoid激活函数(第10行)，从输入层向前推进到隐藏层。结果保存在<code class="fe mv mw mx my b">h_out</code>中(用于<strong class="kc io"> h </strong> idden层<strong class="kc io"> out </strong> put)。因为我们使用的是mathJS' <code class="fe mv mw mx my b">evaluation</code>函数，方便地用<code class="fe mv mw mx my b">e</code>缩写，所以点积公式可以非常直观地写成<code class="fe mv mw mx my b">wih * input</code>。正如您在第8行看到的，您只需要将表达式中使用的所有变量打包到一个对象中，并将其作为mathJS的第二个参数传递，以识别这些值(<code class="fe mv mw mx my b">{wih, input}</code>)。</p><p id="58a8" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">在我看来，能够真正写出微积分表达式对于可读性来说是非常好的，并且有助于从你在深度学习中所学到的东西转换成代码，而不用太担心如何将其转换成正确的编程语言结构。</p><p id="5a7f" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">第11–12行然后用同样的原理从隐藏层向前推进到输出层。</p><p id="acdb" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">最后<code class="fe mv mw mx my b">input</code>、<code class="fe mv mw mx my b">h_out</code>和实际预测值<code class="fe mv mw mx my b">actual</code>都保存在<code class="fe mv mw mx my b">cache</code>(第14-16行)，因为<code class="fe mv mw mx my b">backward</code>法我们以后需要用到它们。</p><p id="1077" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">让我们将正向传播步骤与所有变量和方程映射到网络的插图中:</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi ow"><img src="../Images/db5e2c4db528e60e68e620a8a589f491.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QkV2NrFL3P38DyvIIOmxgg.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">Forward propagation</figcaption></figure><h2 id="eb74" class="nn kz in bd la no np dn le nq nr dp li kl ns nt lm kp nu nv lq kt nw nx lu ny bi translated">反向传播</h2><p id="57d4" class="pw-post-body-paragraph ka kb in kc b kd lw kf kg kh lx kj kk kl ly kn ko kp lz kr ks kt ma kv kw kx ig bi translated"><strong class="kc io">快速重述</strong>:后向传播的目的是将前向传播过程中发现的误差(即神经网络预测值和真实标签值之间的差值)分配给前一层的权重，使得这些权重实际上导致了总的输出误差。通过这样做，权重可以逐渐进行相应的调整，以最小化总体误差。常用的方法是求出误差函数相对于(w.r.t)各层权重(等式左侧)的梯度，通过下面的<a class="ae jz" href="https://www.youtube.com/watch?v=YG15m2VwSjA" rel="noopener ugc nofollow" target="_blank">链式法则</a>公式表示:</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/d0b626ee8161e17e6e9b6e5222f09d44.png" data-original-src="https://miro.medium.com/v2/resize:fit:330/1*udoE9F445bRmnnHy2jX9gw.gif"/></div></figure><p id="9a94" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">在哪里</p><ul class=""><li id="cffb" class="mb mc in kc b kd ke kh ki kl md kp me kt mf kx mg mh mi mj bi translated">e是误差/损失函数，</li><li id="083b" class="mb mc in kc b kd mk kh ml kl mm kp mn kt mo kx mg mh mi mj bi translated">a是激活功能，</li><li id="6305" class="mb mc in kc b kd mk kh ml kl mm kp mn kt mo kx mg mh mi mj bi translated">Z是线性函数(Z = WX，前面关于前向传播的章节已经提到过)和</li><li id="2164" class="mb mc in kc b kd mk kh ml kl mm kp mn kt mo kx mg mh mi mj bi translated">w指一层的重量矩阵</li></ul><p id="846b" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">关于反向传播的进一步阅读:</p><div class="oe of gp gr og oh"><a href="https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/" rel="noopener  ugc nofollow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd io gy z fp om fr fs on fu fw im bi translated">逐步反向传播示例</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">背景反向传播是一种常用的神经网络训练方法。网上不乏这样的论文…</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">mattmazur.com</p></div></div><div class="oq l"><div class="oy l os ot ou oq ov jt oh"/></div></div></a></div><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="oz oa l"/></div></figure><p id="1601" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">反向传播概念被转化为我们的<code class="fe mv mw mx my b">backward</code>方法，它考虑了链式规则公式的所有组成部分:</p><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="25cb" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">现在，让我们通过将链规则与上面摘录的代码联系起来，来分析链规则的不同部分:</p><p id="2adf" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">我们的神经网络的误差函数是:</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/6b243188fc9f22201153a03d6334e98c.png" data-original-src="https://miro.medium.com/v2/resize:fit:424/1*HhmeMy4vtud8TQDDk6xt4g.gif"/></div></figure><p id="dd25" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">输出值<code class="fe mv mw mx my b">actual</code>的梯度通常为:</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/673f2826ab2baea47cb9dd0fcb0d29b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:458/1*y952kvT_ucb3DdUuvlDxtw.gif"/></div></figure><p id="b36a" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">为了简单起见，我们可以去掉常数<code class="fe mv mw mx my b">2</code>，这样梯度就是<code class="fe mv mw mx my b">target — actual</code>(第10行)。我们将它保存在一个名为<code class="fe mv mw mx my b">dEdA</code>的常量中，以便于识别它引用了链式规则公式中的哪个组件。</p><p id="3e5f" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">在我们的输出层中，sigmoid函数的<a class="ae jz" href="https://towardsdatascience.com/derivative-of-the-sigmoid-function-536880cf918e" rel="noopener" target="_blank">梯度</a> A w.r.t其参数Z如下导出并保存在<code class="fe mv mw mx my b">o_dAdZ</code>中，其中<code class="fe mv mw mx my b">o_</code>指的是输出层(第13行):</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/f11ffe5e67af13de163554d054c6d26a.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/1*UUayGDCkM4GxWPAcjrLuAA.gif"/></div></figure><p id="e6d9" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">最后，隐藏到输出层的线性函数Z的梯度w.r.t其权重W就是隐藏层的输出。该值从缓存中提取到<code class="fe mv mw mx my b">h_out</code>(第4行)，我们已经在正向传播过程中保存了该值:</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/239b82dcc6d9cd8c12b0fd6c7546b1c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:230/1*BrgfPg3_86I3vevbinPSEQ.gif"/></div></figure><p id="6635" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">既然我们已经计算了链规则的所有三个不同的组成部分，我们可以将它们放在一起，以获得相对于隐藏到输出层的权重的误差梯度(第18行):</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/435fc5b8636276e3b49361b6d3b252ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/1*h1W3lB_Mcb3BxQ2zFvw_mA.gif"/></div></figure><p id="733d" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">我们不会在这里停下来，而是进一步向后，通过再次计算链规则的不同部分，对隐藏层重复相同的过程。</p><p id="3694" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">这一次，输出的误差梯度w.r.t是从我们的输出层反向传播、加权并保存在名为<code class="fe mv mw mx my b">h_err</code>的常数中的误差，以表示隐藏层误差(第25行):</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/725c2b7e0418e9c55f2ef623e8bba992.png" data-original-src="https://miro.medium.com/v2/resize:fit:586/1*mOuiemXTHVG2wSK3QogLDQ.gif"/></div></figure><p id="631d" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">鉴于这一轮的sigmoid梯度按如下方式导出并保存在<code class="fe mv mw mx my b">h_dAdZ</code>中，其中<code class="fe mv mw mx my b">h_</code>反映隐藏层(第32行):</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/8da8f9536917bbeb9e2a74f4260945aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:490/1*VllCM_DXxix9pTdFNUCVvQ.gif"/></div></figure><p id="be8e" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">线性函数的梯度相对于输入到隐藏层的权重就是<code class="fe mv mw mx my b">input</code>值本身:</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/3602ae0387403b6a0d5313a9bd34d047.png" data-original-src="https://miro.medium.com/v2/resize:fit:232/1*0SII5NUJeyO_4vtzipEh6Q.gif"/></div></figure><p id="7312" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">现在再次量化链规则的所有组件，我们将它们放在一起，以获得相对于输入到隐藏层的权重的误差梯度(第37行):</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/f477e94efab2509a53a64897739ce4c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/1*G8hF_MW9Ba3HBs-taqAzqQ.gif"/></div></figure><p id="9bd5" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">正如你从上面看到的，在我们的两层中的每一层，我们都严格遵循向后传播的链式法则。请注意在代码中使用<code class="fe mv mw mx my b">.*</code>进行元素乘法，而使用<code class="fe mv mw mx my b">*</code>进行两个矩阵的点积。也请不要忽略<code class="fe mv mw mx my b">'</code>符号(如第25行:<code class="fe mv mw mx my b">who'</code>)，它转置一个矩阵。你可以看到，应用mathJS的<code class="fe mv mw mx my b">evaluate</code>函数允许我们使用非常接近真实数学表达式的语法。</p><p id="5ece" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">两个误差梯度都保存在常量<code class="fe mv mw mx my b">dwih</code>(输入到隐藏层权重的误差梯度)和<code class="fe mv mw mx my b">dwho</code>(隐藏到输出层权重的误差梯度)中，并放入缓存中，因为我们稍后需要它们来更新下一节中的权重(第43行&amp; 44)。</p><p id="91ec" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">让我们通过将<code class="fe mv mw mx my b">backward</code>方法中的所有变量和方程映射到我们的网络图来总结反向传播:</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi pj"><img src="../Images/4127af987a4960214d6d424f03f96bf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LSzSv-ZawbjJfCLW5IPh4Q.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">Backward propagation: error propagation</figcaption></figure><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi ow"><img src="../Images/1a5047b56fd25cdc0aab01ea5ec556a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8ZtgUL36Vvj9x6Lu0LxNdQ.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">Backward propagation: error gradients</figcaption></figure><h2 id="f20e" class="nn kz in bd la no np dn le nq nr dp li kl ns nt lm kp nu nv lq kt nw nx lu ny bi translated">更新权重</h2><p id="ff0b" class="pw-post-body-paragraph ka kb in kc b kd lw kf kg kh lx kj kk kl ly kn ko kp lz kr ks kt ma kv kw kx ig bi translated"><strong class="kc io">快速回顾:</strong>经过一次向前和一次向后的传递，我们最终获得梯度，以减少我们当前的重量，这将导致一个步骤，以最小化整体损失。通过应用表示为α的小学习率，用接收到的梯度更新当前权重。通过这样做，我们可以平滑地更新权重，并避免典型的陷阱，如超过最小值。这个过程称为<a class="ae jz" href="https://towardsdatascience.com/gradient-descent-explained-9b953fc0d2c" rel="noopener" target="_blank">梯度下降</a>，描述如下:</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/6747307023776dc5a35fb91f2c97ba0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:386/1*E-6Ir-lWB8gE0E4HsM9HMw.gif"/></div></figure><p id="d039" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">上面的公式通过以下方式转化为我们的<code class="fe mv mw mx my b">update</code>方法:</p><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="dcd6" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">在第8 &amp; 9行，我们用刚刚计算的误差梯度<code class="fe mv mw mx my b">dwih</code>更新了输入到隐藏层<code class="fe mv mw mx my b">wih</code>的当前权重。相同的规则适用于隐藏到输出层<code class="fe mv mw mx my b">who</code>及其误差梯度<code class="fe mv mw mx my b">dwho</code>。代码中两个方程的符号都是正的，因为我们取消了误差梯度，以便在正确的方向上更新，从而找到最小值。如果你对我的解释不满意，我强烈建议你进一步看看吴恩达关于梯度下降背后的直觉的精彩讲解。</p><p id="8b1b" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">就是这样！我们刚刚成功地创建了一个两层神经网络，其中包含了用于训练和测试/预测的所有基本方法。现在让我们看看通过<code class="fe mv mw mx my b">train</code>和<code class="fe mv mw mx my b">predict</code>使用它们有多简单:</p><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="fd49" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">为了训练网络，我们只是进行<code class="fe mv mw mx my b">forward</code>和<code class="fe mv mw mx my b">backward</code>传播和<code class="fe mv mw mx my b">update</code>该序列中的权重(第6–8行)。为了测试网络或从中获得任何预测，我们只需要进行一次<code class="fe mv mw mx my b">forward</code>传播并返回结果(第2行)。</p><p id="2104" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">仅仅几行代码就能构建神经网络这样强大的基础，这难道不令人着迷吗？JavaScript也感觉是非常自然的编程语言。现在让我们利用这个基础。</p></div><div class="ab cl nb nc hr nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ig ih ii ij ik"><h1 id="93ba" class="ky kz in bd la lb ni ld le lf nj lh li lj nk ll lm ln nl lp lq lr nm lt lu lv bi translated">训练和测试神经网络</h1><h2 id="91ae" class="nn kz in bd la no np dn le nq nr dp li kl ns nt lm kp nu nv lq kt nw nx lu ny bi translated">初始化</h2><p id="49c2" class="pw-post-body-paragraph ka kb in kc b kd lw kf kg kh lx kj kk kl ly kn ko kp lz kr ks kt ma kv kw kx ig bi translated">在我们开始任何培训或测试之前，我们需要做一些准备工作。首先，我们需要定制我们的神经网络，用可以处理MNIST数据集的超参数初始化它:</p><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="f85c" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">如前所述，MNIST数据集由28x28灰度图像组成。因此，每个图像有784个像素，这个数字也是我们的输入层的大小(第2行)。对于隐藏层，大小100 <a class="ae jz" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank">已经足够了</a>(第3行)。最终的输出层有10个节点，因为我们希望网络为每个数字(0–9)提供一个概率猜测(第4行)。将应用0.2的学习率(第5行)，并将训练迭代次数设置为5(第6行)。你可以随意摆弄这些数字。</p><p id="ba41" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">第12行包含了最重要的基石:这里我们用所有的超参数从我们的神经网络类中实例化了一个实体<code class="fe mv mw mx my b">myNN</code>,现在可以使用它的所有方法了。</p><p id="3bca" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">让我们展开剩余的初始化代码:</p><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="3fac" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">正如您可以从上述不断初始化中得出的，在我们开始任何训练或测试网络之前，第二步也是最后一步是突出的:我们需要加载和准备我们的MNIST训练和测试数据。让我们仔细看看这是如何做到的:</p><h2 id="6167" class="nn kz in bd la no np dn le nq nr dp li kl ns nt lm kp nu nv lq kt nw nx lu ny bi translated">数据准备</h2><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="a41f" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">上面的<code class="fe mv mw mx my b">loadData</code>函数(第7行&amp; 13)相当简单，我不会在这里解释代码，因为基本上它只是调用JavaScript的<a class="ae jz" href="https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API/Using_Fetch" rel="noopener ugc nofollow" target="_blank">“fetch”</a>函数来获取数据集。请参考<a class="ae jz" href="https://github.com/RyanLinXiang/neural-network-with-js" rel="noopener ugc nofollow" target="_blank">项目的Github库</a>中的完整代码。我们转而关注<code class="fe mv mw mx my b">prepareData</code>(第10行&amp; 16)。下面是该函数的基本代码:</p><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="4232" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">一旦CSV原始文件被加载并传递到<code class="fe mv mw mx my b">prepareData</code>，并且在创建一个数组后，每个元素引用CSV数据的一行(第2行)，使用数组函数<code class="fe mv mw mx my b"><a class="ae jz" href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/indexOf" rel="noopener ugc nofollow" target="_blank">pop</a></code>(第3行)删除最后一个元素是很重要的。这是因为数组的最后一个元素总是空的，由于<code class="fe mv mw mx my b"><a class="ae jz" href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/split" rel="noopener ugc nofollow" target="_blank">split</a></code>函数(第2行)，它引用了CSV文件中的一个空白的最后一行。我们现在可以循环遍历每一行，并从逗号分隔的值创建一个新的数组，其中每个元素的灰度值范围为0–255(第5–14行)。我们不应该忘记通过利用第6行中的<code class="fe mv mw mx my b"><a class="ae jz" href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/map" rel="noopener ugc nofollow" target="_blank">map</a></code>函数(注意前缀<code class="fe mv mw mx my b">+</code>，它是转换为数字的快捷方式)将CSV字符串值转换为数字。</p><p id="c9cb" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">如前所述，MNIST数据集使用每行的第一个字符作为样本的基础事实标签。因此，我们需要提取并删除它，以便只获得颜色值(第8 &amp; 9行)。</p><p id="4d23" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">在第11行，我们调用了<code class="fe mv mw mx my b">myNN</code>的静态<code class="fe mv mw mx my b">normalizeData</code>方法，将输入值标准化到0.01–0.99的范围内。这是一个重要的步骤，尤其是当我们使用sigmoid激活功能时，否则我们的神经网络会达到所谓的<a class="ae jz" href="https://rohanvarma.me/inputnormalization/" rel="noopener ugc nofollow" target="_blank">饱和</a>，其学习能力(=调整其权重)会大大降低:</p><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="54f8" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">标准化之后，数据准备工作就完成了，我们终于可以开始训练我们的网络了！</p><h2 id="1b03" class="nn kz in bd la no np dn le nq nr dp li kl ns nt lm kp nu nv lq kt nw nx lu ny bi translated">培养</h2><p id="64f7" class="pw-post-body-paragraph ka kb in kc b kd lw kf kg kh lx kj kk kl ly kn ko kp lz kr ks kt ma kv kw kx ig bi translated">下面显示了来自<code class="fe mv mw mx my b">train</code>函数的代码摘录。不要把它和我们之前详细讨论过的<code class="fe mv mw mx my b">train</code>方法混淆。这个方法位于我们的神经网络实体<code class="fe mv mw mx my b">myNN</code>内部，不被用户直接调用。为此，下面的<code class="fe mv mw mx my b">train</code>功能作为桥梁:</p><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="31a3" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">因为我们模型的输出层有10个节点，所以我们可以为每个数字(0–9)提供一个概率，我们需要将在数据准备阶段提取的标签号转换为所谓的<a class="ae jz" href="https://medium.com/@michaeldelsole/what-is-one-hot-encoding-and-how-to-do-it-f0ae272f1179" rel="noopener">一个热点向量</a>。例如“3”变成了<code class="fe mv mw mx my b">[0, 0, 0, 0.99, 0, 0, 0, 0, 0, 0]</code>。因此，我们首先需要一个零数组(第8行)，然后给该元素赋值0.99，其索引号3(从0开始计数)恰好是标签号3(第9行)。这种一次性编码是我们的目标，网络预测与其偏差越大，误差就越大。</p><p id="2540" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">第14–16行检查训练周期是否结束，如果结束，调用<code class="fe mv mw mx my b">test</code>分析我们模型的性能。在我们马上到达那里之前，顺便提一下:我们的训练数据集不是批处理的，模型将在训练完每个样本后更新。我这样做是出于简单的原因——请随意编写一个函数，将数据集分成<a class="ae jz" href="https://towardsdatascience.com/batch-mini-batch-stochastic-gradient-descent-7a62ecba642a" rel="noopener" target="_blank">个小批</a>！</p><h2 id="7ccf" class="nn kz in bd la no np dn le nq nr dp li kl ns nt lm kp nu nv lq kt nw nx lu ny bi translated">测试</h2><p id="a790" class="pw-post-body-paragraph ka kb in kc b kd lw kf kg kh lx kj kk kl ly kn ko kp lz kr ks kt ma kv kw kx ig bi translated">每次训练迭代后，调用<code class="fe mv mw mx my b">test</code>函数返回神经网络的当前性能:</p><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="551c" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">如果第二个参数<code class="fe mv mw mx my b">inTraining</code>设置为真，它将调用<code class="fe mv mw mx my b">train</code>继续训练过程(第13–15行)。这就是为什么我们在<code class="fe mv mw mx my b">train</code>函数的代码片段的第15行调用了<code class="fe mv mw mx my b">test("", true)</code>。这也方便地允许我们独立于<code class="fe mv mw mx my b">train</code>调用<code class="fe mv mw mx my b">test</code>，不传递任何东西或者传递一个falsy布尔值作为第二个参数(第1行)。</p><p id="c7fb" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">我们在<code class="fe mv mw mx my b">test</code>中所做的只是遍历整个准备好的测试数据集(第5-16行)。对于每个样本，我们将基础事实标签(第6行)与我们网络的预测(第8行)进行比较，如果匹配(第9行)，则增加<code class="fe mv mw mx my b">correctPredicts</code>。</p><p id="0670" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">我们的模型返回的预测是一个mathJS矩阵，每个数字(0–9)有10个概率(第8行)。应该选择概率最高的数字作为我们的预测。这是在<code class="fe mv mw mx my b">formatPrediction</code>函数中完成的，该函数将网络的预测转换成我们实际可以使用的JavaScript数字:</p><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="00ea" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">首先，我们需要用mathJS' <code class="fe mv mw mx my b">toArray</code>函数将mathJS矩阵转换成JavaScript数组(第2行)。但是这个数组将是二维的，所有的10个概率值占据它们自己的子数组:<code class="fe mv mw mx my b">[ [p1], [p2], ... [p10] ]</code>。因此，我们需要用<code class="fe mv mw mx my b">map</code>(第2行)将所有子数组提取到一个扁平的一维数组中。然后这个展平的数组被展开，每个元素被作为单个参数传递给JavaScript的T4函数，另一方面，它只返回最大值。使用数组函数<code class="fe mv mw mx my b"><a class="ae jz" href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/indexOf" rel="noopener ugc nofollow" target="_blank">indexOf</a></code>,我们可以确定在由10个元素组成的扁平数组中可以找到最高概率值的索引位置，从而得到我们正在寻找的预测数。</p><p id="6265" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">我们已经到达了一个伟大的里程碑。您现在知道了如何用JavaScript构建自己的神经网络，以及如何训练和测试它。请深呼吸，因为你真的可以为你的成就感到骄傲！</p><p id="5809" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">到目前为止，我们所做的一切对用户来说都是不可见的。尚未实现任何用户界面。是的，您可以在NodeJS中运行代码并进行试验。但这不是我们的目标，也不是JavaScript的优势。因此，让我们立即继续实施，并将我们漂亮的神经网络嵌入到一个真实的应用程序中，在我们的情况下，简单的网页允许用户训练和测试模型，以及手写他们的数字，并从网络中获得预测。因为我们使用的是JavaScript，这最后一个实现步骤实际上是最简单的一步，而且非常有趣。</p></div><div class="ab cl nb nc hr nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ig ih ii ij ik"><h1 id="a735" class="ky kz in bd la lb ni ld le lf nj lh li lj nk ll lm ln nl lp lq lr nm lt lu lv bi translated">实现神经网络</h1><p id="62c6" class="pw-post-body-paragraph ka kb in kc b kd lw kf kg kh lx kj kk kl ly kn ko kp lz kr ks kt ma kv kw kx ig bi translated">我们简单的网页由非常基本的HTML/CSS组成，所以我不会在这里深挖，只关注触及我们神经网络的方面。</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi pl"><img src="../Images/7846bf9d1870f6835a6bcba978fa9f6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RSEEHG9yY0lvrg2LOtH-gQ.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">The final web page embedding our neural network</figcaption></figure><p id="20f5" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">我们的web页面的外观只在两个文件中定义:<code class="fe mv mw mx my b">index.html</code>和<code class="fe mv mw mx my b">styles.css</code>。您将在<a class="ae jz" href="https://github.com/RyanLinXiang/neural-network-with-js" rel="noopener ugc nofollow" target="_blank">项目的Github资源库</a>中找到完整的代码。我们之前在所有代码片段中讨论过的神经网络的逻辑被浓缩在<code class="fe mv mw mx my b">nn.js</code>中。我们现在需要将它和mathJS库一起嵌入到<code class="fe mv mw mx my b">index.html</code>中:</p><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="94cd" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">网页主要由<code class="fe mv mw mx my b">div</code>容器和按钮组成，我们通过它们的id选择它们(第6-14行),并将引用保存在常量中，这样我们以后可以更方便地使用它们。最重要的<code class="fe mv mw mx my b">div</code>容器是id为“status”的容器(第6行)。在这里，所有的训练和测试过程都被记录并显示给用户。为了正确工作，我们需要稍微修改一下<code class="fe mv mw mx my b">nn.js</code>中的<code class="fe mv mw mx my b">train</code>和<code class="fe mv mw mx my b">test</code>函数，如下所示:</p><h2 id="69dc" class="nn kz in bd la no np dn le nq nr dp li kl ns nt lm kp nu nv lq kt nw nx lu ny bi translated"><strong class="ak">“列车&amp;测试”功能</strong></h2><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="2584" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">正如你在上面的代码片段中看到的，训练我们模型的所有代码现在都被一个额外的JavaScript <code class="fe mv mw mx my b"><a class="ae jz" href="https://developer.mozilla.org/en-US/docs/Web/API/WindowOrWorkerGlobalScope/setTimeout" rel="noopener ugc nofollow" target="_blank">setTimeout</a></code>函数包装起来，使其成为<a class="ae jz" href="https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Asynchronous" rel="noopener ugc nofollow" target="_blank">异步</a>(第11–20行)。为什么？因为否则的话，在<a class="ae jz" href="https://exploringjs.com/impatient-js/ch_async-js.html#blocking-browsers" rel="noopener ugc nofollow" target="_blank">阻塞</a> <code class="fe mv mw mx my b">forEach</code>循环完全执行之前，网页的呈现不会用我们的日志消息更新(第17行)。但是我们希望从我们的<code class="fe mv mw mx my b">train</code>函数中不时地得到一个生命信号——在我们可以在像<code class="fe mv mw mx my b">printSteps</code>这样的变量中定义的间隔内(例如每1000个样本)。为此，我们需要将循环中的阻塞代码转换为非阻塞异步代码，例如使用<code class="fe mv mw mx my b">setTimeout</code>。这同样适用于<code class="fe mv mw mx my b">test</code>函数，因为我们希望它在分析网络性能时以一定的时间间隔向我们报告:</p><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="6d5b" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">附带说明:由于异步的性质，我们实际上可以在网络仍在训练时画一个数字，并根据当前训练的权重得到一个“实时”预测。能够在训练过程中使用基于神经网络的应用程序，这难道不令人惊讶吗？</p><p id="248a" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">经过这些修改后，我们只需将这两个函数连接到它们对应按钮的事件监听器:</p><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="4bc6" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">请自己尝试一下:一旦你点击“训练”按钮，训练将立即开始，并在灰色的“状态”<code class="fe mv mw mx my b">div</code>容器中记录进度。一旦你点击“测试”，它将立即开始测试当前的重量，并记录进度。当然，只有当训练更加进步并且误差变得更低时，网络才会产生有意义的结果:</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/95d26d2cc1121143e4793c8edd11a6e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*4bqoOdYLWYl8HxRDrT2-_Q.png"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">“Train” feature</figcaption></figure><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/ed8c3c5771b42ccaacca5f72b1f3cffa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*YcUnGOJZQatKiWH0qYDxfg.png"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">“Test” feature</figcaption></figure><h2 id="9a8f" class="nn kz in bd la no np dn le nq nr dp li kl ns nt lm kp nu nv lq kt nw nx lu ny bi translated">表演</h2><p id="e8d5" class="pw-post-body-paragraph ka kb in kc b kd lw kf kg kh lx kj kk kl ly kn ko kp lz kr ks kt ma kv kw kx ig bi translated">我们对MNIST数据集的训练将需要一些时间，这取决于您的计算机的性能，在使用前面提到的默认超级参数进行5次迭代后，最终准确率应该在97%左右:</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div class="gh gi po"><img src="../Images/1ef1a5b6642aa7a11a42c32fca8247bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/1*4MLXwUrHKg3nKvlGooZnVQ.png"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">Final result</figcaption></figure><h2 id="6117" class="nn kz in bd la no np dn le nq nr dp li kl ns nt lm kp nu nv lq kt nw nx lu ny bi translated">“预测”功能</h2><p id="98af" class="pw-post-body-paragraph ka kb in kc b kd lw kf kg kh lx kj kk kl ly kn ko kp lz kr ks kt ma kv kw kx ig bi translated">当我们的网络在训练时，让我们继续构建我们的单页应用程序的中心功能:一个黑色画布，用户可以用鼠标画一个白色的数字，点击“预测”按钮，从我们的神经网络中得到一个猜测。让我们用一个截图来概括一下这个特性:</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/639d2ab6c561f9970109f1569c55c1ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*bHU0_niN6k0IwTbHOOItoA.png"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">“Predict” feature</figcaption></figure><p id="605a" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">画布本身由简单的HTML/JavaScript实现，您可以在最终代码中找到实现。我们更感兴趣的是如何以一种我们的神经网络可以理解的方式转换画布数据，并根据它们做出预测:</p><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="f32c" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">因为28x28像素的图像非常小，所以我们需要更大的绘图区域。这里我选择了150x150像素的画布。为了将其调整到训练数据图像的大小，我们首先需要创建第二个画布(第3 &amp; 4行)，然后应用<code class="fe mv mw mx my b"><a class="ae jz" href="https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/drawImage" rel="noopener ugc nofollow" target="_blank">drawImage</a></code>函数，该函数将原始的<code class="fe mv mw mx my b">canvas</code>作为参数，并输出一个新的调整大小的图像(第5行)。</p><p id="2daf" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">之后，我们可以使用<code class="fe mv mw mx my b"><a class="ae jz" href="https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/getImageData" rel="noopener ugc nofollow" target="_blank">getImageData</a></code>将画布图像转换成一个特殊的<code class="fe mv mw mx my b">ImageData</code>对象，该对象包含一个<code class="fe mv mw mx my b">data</code>数组(第8行)。对于图像中的每个单个像素，该阵列有4个相应的颜色值，范围从0到255，涉及每个<a class="ae jz" href="https://en.wikipedia.org/wiki/RGBA_color_model" rel="noopener ugc nofollow" target="_blank">RGBA</a>(R =红色，G =绿色，B =蓝色，A=alpha)通道。这就是为什么<code class="fe mv mw mx my b">data</code>数组的长度是3136(= 28 x28 x4)。因此，我们的目标是将其减少到我们网络的输入大小784 (=28x28x1)，因为我们只需要灰度颜色通道。</p><p id="a0c5" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">这里的方法是只计算三个RGB通道的平均值，将它作为我们的灰度值，并在alpha通道上循环(第12–14行)。</p><p id="bc24" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">在将我们的值传递给我们网络的<code class="fe mv mw mx my b">predict</code>方法之前，我们不能忘记标准化我们的值，以便与训练数据具有相同的值范围(第16行)。网络的预测然后再次由<code class="fe mv mw mx my b">formatPrediction</code>格式化，如之前已经解释的，并最终显示在页面的“预测”<code class="fe mv mw mx my b">div</code>容器中(第19行)。</p><p id="39a4" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">最后，我们只需要将<code class="fe mv mw mx my b">predict</code>函数连接到相应“预测”按钮的事件监听器，如第8行所示:</p><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="a6d7" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">瞧啊！我们做到了，一旦训练结束，它就会像魔法一样发挥作用！通过一些点积和反向传播计算，您可以获得非凡的成果:</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/0b62d3e5856efec0ff469f6a44d9ebdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:584/format:webp/1*SgMYqnf3QPlT-lihY5JILg.png"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">Final predictions for all digits</figcaption></figure><h2 id="5e41" class="nn kz in bd la no np dn le nq nr dp li kl ns nt lm kp nu nv lq kt nw nx lu ny bi translated">“保存/加载重量”功能</h2><p id="7d4b" class="pw-post-body-paragraph ka kb in kc b kd lw kf kg kh lx kj kk kl ly kn ko kp lz kr ks kt ma kv kw kx ig bi translated">我们的应用程序中包含的最后一个突出特性是，在耗时的训练过程完成后，让用户有机会保存重量并从外部文件加载它们。通过这样做，模型可以(重新)用于预测，我们不必在每次重新加载页面时重新训练它。此外，我们还可以方便地与他人分享重量。为此，让我们最后一次塑造我们的<code class="fe mv mw mx my b">test</code>函数，并从内部调用一个新函数<code class="fe mv mw mx my b">createDownLoadLink</code>:</p><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="e418" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">一旦我们检查了培训是否完成，并且没有进一步的<code class="fe mv mw mx my b">test</code>调用(第9-11行)，我们就调用<code class="fe mv mw mx my b">createDownloadLink</code>(第10行)来混合一个下载链接。这可以通过从我们的神经网络的<code class="fe mv mw mx my b">myNN</code>实体(第19行&amp; 20)中提取最新的权重，并通过“下载”属性(第22–24行)将它们字符串化为HTML锚元素来轻松完成。现在，每次完成训练后，都会显示“下载模型重量”链接:</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/06ecc8819c57a6aed726b4dca999b3d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*lkjRMRAUHf9mvrQ2pd2WaQ.png"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">Link to download trained model weights</figcaption></figure><p id="f4c8" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">为了让用户能够将刚刚保存的JSON文件加载到神经网络中，让我们最后一次重新访问网络的初始化代码，并添加以下内容:</p><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="386f" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">如果在初始化时发现JSON文件，它将被保存在常量<code class="fe mv mw mx my b">savedWeights</code>(第10–12行)中。现在，一旦用户点击“加载重量”按钮，应执行以下功能:</p><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="c53a" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">从上面的代码中可以看出，在我们的神经网络实体<code class="fe mv mw mx my b">myNN</code>中，输入到隐藏层(<code class="fe mv mw mx my b">wih</code>)以及隐藏到输出层(<code class="fe mv mw mx my b">who</code>)的权重被<code class="fe mv mw mx my b">savedWeights</code>的值覆盖。当然，这里的最后一步是添加另一个事件监听器，并将其与<code class="fe mv mw mx my b">loadWeights</code>函数及其相应的按钮链接起来(如下第8行):</p><figure class="mq mr ms mt gt jo"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="baf5" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">现在，当您点击“加载权重”按钮时，将显示以下消息，您可以立即开始绘制，以获得基于加载权重的预测:</p><figure class="mq mr ms mt gt jo gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/683bd0f37d65a11f56bdf579d4c4760d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1178/format:webp/1*i2_zLsLrs0NA_e62xuOXUQ.png"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">“Load weights” feature</figcaption></figure><p id="1b93" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">恭喜你！如果你遵循了所有的步骤，你现在不仅对如何用JavaScript构建、测试和训练你自己的神经网络有了很好的理解，而且对如何把你的模型变成一个真正的应用程序也有了很好的理解！这是实现你所有令人兴奋的想法的坚实基础！这篇文章真的很全面，但我不能决定删除任何内容，因为我真的想给你一个这个非常深刻和有趣的主题的完整概述。</p><p id="5611" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">我从心底里是一名JavaScript开发人员，我希望在阅读完这篇文章后，您会同意JavaScript是实现令人兴奋的应用程序的自然选择，这些应用程序带有可以在任何地方运行的人工智能。在我看来，JavaScript和机器学习的耦合仍然是一个提供巨大潜力的未知领域，特别是随着深度学习框架的引入，如<a class="ae jz" href="https://www.tensorflow.org/js" rel="noopener ugc nofollow" target="_blank"> Tensorflow.js </a>。</p><p id="064a" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">如果您已经完全理解了我在本文中提到的概念和代码，没有什么能阻止您构建更复杂的模型来解决更复杂的问题。因此，感谢您的关注和耐心。请不要犹豫，把你的问题贴在这里。我也非常期待你的反馈和评论，迫不及待想看到你用JavaScript实现神经网络应用程序！</p></div><div class="ab cl nb nc hr nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ig ih ii ij ik"><h1 id="f5e4" class="ky kz in bd la lb ni ld le lf nj lh li lj nk ll lm ln nl lp lq lr nm lt lu lv bi translated">项目存储库</h1><p id="b82c" class="pw-post-body-paragraph ka kb in kc b kd lw kf kg kh lx kj kk kl ly kn ko kp lz kr ks kt ma kv kw kx ig bi translated">您可以在<a class="ae jz" href="https://github.com/RyanLinXiang/neural-network-with-js" rel="noopener ugc nofollow" target="_blank">项目的Github知识库</a>中找到完整的代码，包括所有的注释。在那里您还可以找到<code class="fe mv mw mx my b">nn.js</code>的高级版本，在那里您可以随时中止训练，但仍然可以下载在此之前训练过的重量。</p><p id="00d1" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">我还在<code class="fe mv mw mx my b">dist/</code>文件夹中放入了一个<code class="fe mv mw mx my b">weights.json</code>文件，其经过训练的权重达到了所提到的约97%的准确度，供您直接加载到神经网络中。</p><p id="6598" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">您将需要MNIST数据集(train和test)作为CSV版本，由于其大小而不包括在存储库中。请直接从<a class="ae jz" href="https://pjreddie.com/projects/mnist-in-csv/" rel="noopener ugc nofollow" target="_blank"> pjreddie </a>下载。</p><p id="841f" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">当您在本地运行这个项目时，您将需要在本地web服务器上运行它。否则，项目通过<code class="fe mv mw mx my b">fetch</code>对本地文件的访问将无法工作，因为它需要服务器提供文件服务..最简单的方法是设置<a class="ae jz" href="https://chrome.google.com/webstore/detail/web-server-for-chrome/ofhbbkphhbklhfoeikjpcbhemlocgigb?hl=en" rel="noopener ugc nofollow" target="_blank">“Chrome Web服务器”</a>。如果您遇到任何问题，请在此处留言。</p><h1 id="2c2a" class="ky kz in bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">限制</h1><p id="7535" class="pw-post-body-paragraph ka kb in kc b kd lw kf kg kh lx kj kk kl ly kn ko kp lz kr ks kt ma kv kw kx ig bi translated">神经网络的训练不利用任何硬件加速，因此将需要很长时间来完成，尤其是考虑到60，000个样本的数量。对于更复杂的模型，你将最终使用深度学习框架，如<a class="ae jz" href="https://www.tensorflow.org/js" rel="noopener ugc nofollow" target="_blank"> Tensorflow.js </a>，它也提供GPU支持。此外，用户的手绘可能与训练图像有很大不同，例如，它们可能非常小或不够居中(这个问题已经在StackOverFlow的<a class="ae jz" href="https://stackoverflow.com/questions/59535286/improve-real-life-results-of-neural-network-trained-with-mnist-dataset" rel="noopener ugc nofollow" target="_blank">这里</a>解决了)，这可能导致错误的预测。为了简单起见，我们没有在代码中解决这些问题。我这篇文章的目标不是构建完美的模型，而是更加关注用JavaScript实现神经网络。希望通过自己制作一个模型和一个应用程序来帮助你扩展你的知识。</p><h1 id="ff39" class="ky kz in bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">承认</h1><ul class=""><li id="806b" class="mb mc in kc b kd lw kh lx kl pt kp pu kt pv kx mg mh mi mj bi translated">塔里克·拉希德(Tariq Rashid)写的这本精彩易懂的书<a class="ae jz" href="http://makeyourownneuralnetwork.blogspot.co.uk" rel="noopener ugc nofollow" target="_blank">“打造你自己的神经网络”，让我第一次真正“明白”了神经网络实际上为什么以及如何工作。</a></li><li id="673b" class="mb mc in kc b kd mk kh ml kl mm kp mn kt mo kx mg mh mi mj bi translated">格兰特·桑德森制作的非常漂亮的视频系列<a class="ae jz" href="https://www.youtube.com/c/3blue1brown" rel="noopener ugc nofollow" target="_blank">“3 blue 1 brown”</a>，我第一次真正“明白”微积分<a class="ae jz" href="https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr" rel="noopener ugc nofollow" target="_blank">和线性代数</a><a class="ae jz" href="https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab" rel="noopener ugc nofollow" target="_blank">实际上是如何工作的。</a></li><li id="bfed" class="mb mc in kc b kd mk kh ml kl mm kp mn kt mo kx mg mh mi mj bi translated">有史以来最好的深度学习老师:<a class="ae jz" href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwjP97jq-LXvAhWRYMAKHTP-C6QQFjAAegQIAhAD&amp;url=https%3A%2F%2Fde.wikipedia.org%2Fwiki%2FAndrew_Ng&amp;usg=AOvVaw30UIYDUGmhrLKmRo5D6Neg" rel="noopener ugc nofollow" target="_blank">吴恩达</a>。他的课程<a class="ae jz" href="https://www.coursera.org/learn/machine-learning" rel="noopener ugc nofollow" target="_blank">“机器学习”</a>和<a class="ae jz" href="https://www.coursera.org/specializations/deep-learning" rel="noopener ugc nofollow" target="_blank">“深度学习专门化”</a>在<a class="ae jz" href="https://coursera.org" rel="noopener ugc nofollow" target="_blank"> Coursera </a>上，如果你想真正理解机器学习背后的概念和数学，特别是深度学习，这是必须的。</li></ul></div></div>    
</body>
</html>